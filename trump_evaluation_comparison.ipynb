{"cells":[{"cell_type":"markdown","metadata":{"id":"W9fqt5Q4p3-H"},"source":["# Trump Speech Style Evaluation: Fine-tuned Model vs Few-shot Prompting\n","\n","This notebook compares the performance of a fine-tuned Trump speech model against few-shot prompting using a base language model. We'll evaluate both approaches using linguistic alignment metrics to determine which better captures Trump's speaking style.\n","\n","## Evaluation Metrics\n","- **Lexical Features**: Nouns, verbs, adjectives, unique words, subjectivity, concreteness\n","- **Syntactic Features**: Sentence complexity distribution (simple, compound, complex, complex-compound)\n","- **Surface Features**: Punctuation usage, word count, word length\n","- **Overall Similarity**: Cosine similarity and alignment scores\n"]},{"cell_type":"code","source":["!pip install stanza\n","!pip install unsloth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4nHHDNEqLqp","executionInfo":{"status":"ok","timestamp":1757793570156,"user_tz":-120,"elapsed":22109,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"c5feabcb-556c-4094-c35b-6f92fc53b8a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stanza\n","  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n","Collecting emoji (from stanza)\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from stanza) (2.0.2)\n","Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.12/dist-packages (from stanza) (5.29.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from stanza) (2.32.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from stanza) (3.5)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from stanza) (2.8.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stanza) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (3.4.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->stanza) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->stanza) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->stanza) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->stanza) (2025.8.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3.0->stanza) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n","Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji, stanza\n","Successfully installed emoji-2.14.1 stanza-1.10.1\n","Collecting unsloth\n","  Downloading unsloth-2025.9.4-py3-none-any.whl.metadata (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting unsloth_zoo>=2025.9.5 (from unsloth)\n","  Downloading unsloth_zoo-2025.9.5-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n","Collecting xformers>=0.0.27.post2 (from unsloth)\n","  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n","Collecting bitsandbytes (from unsloth)\n","  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n","Collecting tyro (from unsloth)\n","  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.56.1)\n","Collecting datasets<4.0.0,>=3.4.1 (from unsloth)\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.10.1)\n","Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n","  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n","Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.34.4)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.19.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth) (0.22.0)\n","Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.9.5->unsloth) (0.10.0)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2025.9.5->unsloth)\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.9.5->unsloth) (11.3.0)\n","Collecting msgspec (from unsloth_zoo>=2025.9.5->unsloth)\n","  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (13.9.4)\n","Collecting shtab>=1.5.6 (from tyro->unsloth)\n","  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.15)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.8.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\n","Downloading unsloth-2025.9.4-py3-none-any.whl (313 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2025.9.5-py3-none-any.whl (206 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.1/206.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n","Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: shtab, msgspec, tyro, xformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 4.0.0\n","    Uninstalling datasets-4.0.0:\n","      Successfully uninstalled datasets-4.0.0\n","Successfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 datasets-3.6.0 msgspec-0.19.0 shtab-1.7.2 trl-0.23.0 tyro-0.9.31 unsloth-2025.9.4 unsloth_zoo-2025.9.5 xformers-0.0.32.post2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKn-VPsfq2uL","executionInfo":{"status":"ok","timestamp":1757793735051,"user_tz":-120,"elapsed":23994,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"d8f8ba60-1c02-4c0e-d79f-461543a86d49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476,"referenced_widgets":["de23e7aa5f314995b7c89f1c87399879","221590283afd47f8800296dc5ae69f73","e4ab0f0de7cd4c05a7f1ebc0d7211303","bd69af67145a4e87bb71da7f83f5f06b","8854cf454ead4bb3b4630ea7d5008ec2","4f71294bfeae422f953552f622e3c42e","1fffa730b6b648e58ed8fb05153decea","14b9a426a55c4e2bb5858ac24393a2b4","1a028836cf18415e9ff889ebc6c4750c","89b96fbc476b451c9ebc9d1be2188ca0","8957c3e861d148889dff506c028f1f82","f88e8611064543d0847de4960b519a58","c53e4d885f25438da3b4e55955a31237","849d48bded1241e2b5d2beb4f8540676","41c93904260b4b94b63149c26b4a05fe","8de41910efa94d59a7fd3a2c197951e7","e88f9eb8c7a149ab96546042a97366d4","6ba3c3ec3c484a50898a9a0286fac89c","2f68ec3884d64c71bb993920cf678a11","94136f2345094280a336808c6a49ff7b","a59e3a4809ba4cb1884d048575d58c5e","dda632afe7f644c780797788f48862f9"]},"id":"14skpMAyp3-K","executionInfo":{"status":"ok","timestamp":1757793633701,"user_tz":-120,"elapsed":39504,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"616c31e6-f1c1-4d93-bf4a-efbfd8f6b755"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1071013500.py:19: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n","\n","Please restructure your imports with 'import unsloth' at the top of your file.\n","  from unsloth import FastLanguageModel\n"]},{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de23e7aa5f314995b7c89f1c87399879"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n","INFO:stanza:Downloading default packages for language: en (English) ...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip:   0%|          | …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88e8611064543d0847de4960b519a58"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /root/stanza_resources/en/default.zip\n","INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n"]},{"output_type":"stream","name":"stdout","text":["Libraries imported successfully!\n"]}],"source":["# Import required libraries\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.tree import Tree\n","from textblob import TextBlob\n","import stanza\n","from tqdm import tqdm\n","from scipy.spatial.distance import jensenshannon\n","import torch\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime\n","\n","# Import your model loader from unsloth\n","from unsloth import FastLanguageModel\n","\n","# Download required NLTK resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')\n","\n","# Download English models for Stanza\n","stanza.download('en')\n","\n","print(\"Libraries imported successfully!\")\n"]},{"cell_type":"markdown","metadata":{"id":"NRD-7GX3p3-M"},"source":["## 1. Model Loading and Configuration\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKdRCyzOp3-N","executionInfo":{"status":"ok","timestamp":1757794251728,"user_tz":-120,"elapsed":10,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"90008090-e893-4d7f-c849-963bf0878a93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration loaded:\n","  finetuned_model_dir: /content/drive/MyDrive/trump_model/trump_model_14B/outputs\n","  baseline_csv: /content/drive/MyDrive/trump_model/data/preprocessed_trump.csv\n","  num_baseline_samples: 10\n","  max_length: 300\n","  temperature: 1.0\n","  top_p: 0.95\n","  top_k: 50\n"]}],"source":["# Configuration\n","CONFIG = {\n","    'finetuned_model_dir': '/content/drive/MyDrive/trump_model/trump_model_14B/outputs',\n","    'baseline_csv': '/content/drive/MyDrive/trump_model/data/preprocessed_trump.csv',\n","    'num_baseline_samples': 10,\n","    'max_length': 300,\n","    'temperature': 1.0,\n","    'top_p': 0.95,\n","    'top_k': 50\n","}\n","\n","print(\"Configuration loaded:\")\n","for key, value in CONFIG.items():\n","    print(f\"  {key}: {value}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":492,"referenced_widgets":["d938276bde8240a9bc3c2acb935f4110","fa0bd3359a6e43b6ade91b852086591f","b705d26e3f85461fb64544b452337f4f","1f3a2acbb3424589bf1b321bdb11d689","13af0579f7f34df3be3ac73965231764","3ab22ddb023843489aba7b3cf59aa347","2cfeb6566641444ba9786f23d6bf8078","383104f77d02481086dec717da46df0c","f6f23160ebfe43dc84fce88decc8eac4","4ed7eb97a1784e60bb8922d2670632ad","de1d94a80c4f46a1b677186c1820430c","6a932fc4c6d541e7b5976d79736fc71a","56cd00e7a2ef406ca600c04f9d9df43d","0e5806f10ec240ef800a64ab22bc9b69","7ee1fecf3ca847828f19925a5b7aba9f","69ad5b718e754ae5a70c6200a6db5866","95331fa9a201482f985ddbd2da00a931","1e198f0a5b56408eb0986cab13f70d75","2ab2843971c843c59caed66da4efa431","4ba20949ccec47788497e8ee887383c6","be8af869f99943a19fc657d5ed7e329e","c41919c519c9423e99bbf9907db510dd"]},"id":"cIdMjReIp3-N","executionInfo":{"status":"ok","timestamp":1757794287160,"user_tz":-120,"elapsed":33925,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"4c8fa7aa-77b7-4a61-f9a1-80c67e16a21a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading fine-tuned model...\n","Loading fine-tuned model from: /content/drive/MyDrive/trump_model/trump_model_14B/outputs\n","Direct loading failed: 'NoneType' object has no attribute 'get'\n","Trying alternative approach...\n","Loading base model: unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit\n","==((====))==  Unsloth 2025.9.4: Fast Qwen2 patching. Transformers: 4.56.1.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d938276bde8240a9bc3c2acb935f4110"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading PEFT adapter from: /content/drive/MyDrive/trump_model/trump_model_14B/outputs\n","\n","Loading base model for few-shot prompting...\n","Loading base model for few-shot prompting...\n","==((====))==  Unsloth 2025.9.4: Fast Qwen2 patching. Transformers: 4.56.1.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a932fc4c6d541e7b5976d79736fc71a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","✅ Models loaded successfully!\n"]}],"source":["def load_finetuned_model(model_dir):\n","    \"\"\"Load the fine-tuned model and tokenizer.\"\"\"\n","    print(f\"Loading fine-tuned model from: {model_dir}\")\n","\n","    try:\n","        # Try the direct approach first\n","        model, tokenizer = FastLanguageModel.from_pretrained(\n","            model_name=model_dir,\n","            max_seq_length=2048,\n","            dtype=None,\n","            load_in_4bit=True\n","        )\n","        model = FastLanguageModel.for_inference(model)\n","        return model, tokenizer\n","    except Exception as e:\n","        print(f\"Direct loading failed: {e}\")\n","        print(\"Trying alternative approach...\")\n","\n","        # Alternative approach: load base model + adapter\n","        base_model_name = \"unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit\"\n","        print(f\"Loading base model: {base_model_name}\")\n","        model, tokenizer = FastLanguageModel.from_pretrained(\n","            model_name=base_model_name,\n","            max_seq_length=2048,\n","            dtype=None,\n","            load_in_4bit=True\n","        )\n","\n","        # Load the PEFT adapter\n","        print(f\"Loading PEFT adapter from: {model_dir}\")\n","        from peft import PeftModel\n","        model = PeftModel.from_pretrained(model, model_dir)\n","\n","        model = FastLanguageModel.for_inference(model)\n","        return model, tokenizer\n","\n","def load_base_model():\n","    \"\"\"Load a base model for few-shot prompting.\"\"\"\n","    print(\"Loading base model for few-shot prompting...\")\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name=\"unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit\",\n","        max_seq_length=2048,\n","        dtype=None,\n","        load_in_4bit=True\n","    )\n","    model = FastLanguageModel.for_inference(model)\n","    return model, tokenizer\n","\n","# Load models\n","print(\"Loading fine-tuned model...\")\n","finetuned_model, finetuned_tokenizer = load_finetuned_model(CONFIG['finetuned_model_dir'])\n","\n","print(\"\\nLoading base model for few-shot prompting...\")\n","base_model, base_tokenizer = load_base_model()\n","\n","print(\"\\n✅ Models loaded successfully!\")\n"]},{"cell_type":"markdown","metadata":{"id":"izWGVaGtp3-O"},"source":["## 2. Few-shot Prompting Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqXg2zBqp3-O","executionInfo":{"status":"ok","timestamp":1757794343268,"user_tz":-120,"elapsed":84,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"00b5a1a1-42db-4ec5-cc7d-f9eae22b4bd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Few-shot prompt template loaded successfully!\n"]}],"source":["# Few-shot prompting template\n","FEW_SHOT_PROMPT = \"\"\"Final Prompt for Learning and Mimicking Donald Trump's Speech Style\n","Below are seven examples that capture key elements of Donald Trump's speaking style. Study these examples carefully to understand the tone, structure, and language. Then, using these stylistic markers, generate an original political rally speech in Trump's style.\n","\n","Example 1: Extended Greetings and Gratitude with Local Connection\n","\"Thank you, everybody. Thank you so much for being here tonight. Thank you and Vice President Mike Pence—thank you very much! It's absolutely incredible. And hello to Fayetteville, hello to every hardworking patriot in this great part of the country! We're here together, representing faith, family, God, and country, and it fills me with pride. You're the backbone of America, and tonight, we celebrate the spirit of our communities that have always put this nation first.\"\n","Key Elements:\n","* Multiple enthusiastic greetings and expressions of gratitude\n","* Direct address to the local audience\n","* Emphasis on American values (faith, family, God, country)\n","\n","Example 2: Rallying Around Elections and Economic Achievements\n","\"Tomorrow, each and every one of you will head to the polls to elect leaders who always put America first. We've created six million new jobs since election day—six million! More Americans are working today than ever before in our country's history. We've taken this big, beautiful ship and turned it around so quickly that nobody saw it coming. Every job, every opportunity is a testament to your hard work and our unbeatable vision for America. It's tremendous progress, and it's only the beginning!\"\n","Key Elements:\n","* Clear call-to-action regarding elections\n","* Use of striking numbers and hyperbolic language (\"big, beautiful ship\")\n","* Emphasis on unprecedented economic success and recovery\n","\n","Example 3: Addressing Challenges with Confidence and Resilience\n","\"I've just come from a meeting with officials from communities hit hard by Hurricane Dorian. I told them, 'We're behind you 100%—100%!' Yes, North Carolina got hit hard, maybe harder than anyone expected, but if there's one thing I know about this state, it's that you bounce back stronger, quicker, and better than ever. I've seen it before, and I know it will happen again. Together, with the strength of the American spirit, we're going to rebuild faster than anyone thought possible, and it will be beautiful!\"\n","Key Elements:\n","* Repetition of numbers for dramatic emphasis\n","* Acknowledgment of hardship followed by unwavering optimism\n","* Inspiring tone that reassures the audience of their resilience\n","\n","Example 4: Boasting National Strength and International Respect\n","\"We have the number one economy anywhere in the world—truly number one. Every time I meet a foreign leader, they tell me, 'Congratulations on what you've done with the economy.' And I say, 'I didn't do it alone; it was the American people.' Our military is stronger than ever, our borders are secure, and every nation respects America again. We're winning on all fronts, and let me tell you, the world is taking notice. Our success isn't just felt at home—it's echoed across the globe!\"\n","Key Elements:\n","* Use of superlatives and bold statements (\"number one economy\")\n","* Emphasis on international validation and respect\n","* A confident tone that credits the American people\n","\n","Example 5: Contrasting the Opposition and Rallying Defenders of American Values\n","\"But let me be clear—the radical left and the fake news media want to dismantle everything we've built. They're out to tear down our successes, our freedoms, and the very spirit that makes America great. They push policies that will destroy jobs, weaken our borders, and compromise our future. We cannot, and we will not, let them win. We have to stand strong and choose leaders who defend our values. We're fighting for our country, and together, we're going to protect every achievement that makes America the shining beacon of freedom that it is!\"\n","Key Elements:\n","* Clear dichotomy between \"us\" and \"them\"\n","* Vivid negative portrayal of opponents with assertive language\n","* A strong call-to-action focused on defending American values\n","\n","Example 6: Reinforcing Catchy Slogans and National Pride\n","\"Make America great again—these are not just words; they're a movement! Our slogan is the greatest in the history of politics, and it reminds us every day of the incredible work we're doing. While other slogans have come and gone, this one endures because it speaks to the heart and soul of every American. We're not going to change it. Instead, we're going to build on it to keep America great. Our country is winning, our communities are thriving, and we will never settle for anything less than excellence!\"\n","Key Elements:\n","* Repetition of the slogan for maximum impact\n","* Reinforcement of national pride and continuity of success\n","* Contrast with less effective alternatives using humor and conviction\n","\n","Example 7: Personal Criticism of Opponents and International Comparison\n","\"Let's be honest—Sleepy Joe is simply not up to the task. He's been all over the place, changing his mind at every turn, and making excuses when real solutions are needed. Meanwhile, I've built relationships with the world's most powerful leaders—President Xi of China, President Putin of Russia—and they know what strong leadership looks like. Unlike those who waver and doubt, I stand firm, putting America first every single day. We need a leader who delivers results, who is respected on the global stage, and who will never let our country down!\"\n","Key Elements:\n","* Direct, personal criticism using memorable nicknames\n","* Contrast between the speaker's decisiveness and the opponent's inconsistency\n","* Reference to international relationships to emphasize leadership strength\n","\n","Instruction for the LLM:\n","Using the guidelines and style elements provided above through the examples, write a 500–700 word political rally speech in the unmistakable style of Donald Trump. Your speech should focus on a contemporary topic of national importance (such as economic recovery, national security, or election themes) and must include the following:\n","* Extended Greetings and Gratitude: Begin with multiple, enthusiastic greetings and thank-yous, addressing local communities by name.\n","* Patriotism and National Pride: Emphasize core values like faith, family, God, and country, and use superlatives to highlight American achievements.\n","* Bold Claims and Hyperbolic Statements: Incorporate striking numbers, repetition (like \"100%\" or \"six million new jobs\"), and memorable slogans such as \"Make America great again\" or \"Keep America great.\"\n","* Contrast with Opponents: Clearly differentiate between \"us\" and \"them,\" using direct, personal criticism of political opponents (with nicknames if appropriate) and contrasting language.\n","* Direct Call-to-Action: Reference upcoming elections or important decisions, urging immediate action from the audience.\n","* International and Economic Bravado: Mention international respect, interactions with foreign leaders, and boast about economic successes.\n","* Confident, Assertive Tone with Repetition: Maintain a punchy, confident tone throughout, ensuring key points are repeated for impact.\n","\n","Now, write a speech on the following topic:\"\"\"\n","\n","print(\"Few-shot prompt template loaded successfully!\")\n"]},{"cell_type":"markdown","metadata":{"id":"tMEjGEnfp3-S"},"source":["## 3. OpenAI API Integration for Few-shot Prompting\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RzgHKIQp3-T","executionInfo":{"status":"ok","timestamp":1757795645723,"user_tz":-120,"elapsed":59,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"da1e623a-673b-4d46-a983-5225d8bc7a84"},"outputs":[{"output_type":"stream","name":"stdout","text":["OpenAI API integration ready!\n"]}],"source":["# OpenAI API setup\n","import openai\n","from openai import OpenAI\n","import json\n","import time\n","\n","# Set your OpenAI API key\n","# You can set this as an environment variable: export OPENAI_API_KEY=\"your-key-here\"\n","# Or replace with your actual key (not recommended for production)\n","openai.api_key = \"\"\n","client = OpenAI(api_key=openai.api_key)\n","\n","def generate_with_openai(prompt, model=\"gpt-4\", max_tokens=1000, temperature=0.8):\n","    \"\"\"Generate text using OpenAI API with few-shot prompting.\"\"\"\n","    try:\n","        response = client.chat.completions.create(\n","            model=model,\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are an expert at mimicking Donald Trump's speaking style. Generate political speeches that capture his unique tone, vocabulary, and rhetorical patterns.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ],\n","            max_tokens=max_tokens,\n","            temperature=temperature,\n","            top_p=0.9\n","        )\n","        return response.choices[0].message.content.strip()\n","    except Exception as e:\n","        print(f\"Error generating with OpenAI: {e}\")\n","        return None\n","\n","print(\"OpenAI API integration ready!\")\n"]},{"cell_type":"markdown","metadata":{"id":"Y-RJPCY_p3-V"},"source":["## 4. Linguistic Evaluation Functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"envvDPgAp3-V","executionInfo":{"status":"ok","timestamp":1757795651719,"user_tz":-120,"elapsed":13,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"af397e18-9364-42b1-f096-26e85394c2ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text generation functions ready!\n"]}],"source":["# Text generation functions\n","def generate_finetuned_text(prompt, model, tokenizer, max_length=300):\n","    \"\"\"Generate text using the fine-tuned model.\"\"\"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    input_ids = inputs.input_ids\n","\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","        input_ids = input_ids.cuda()\n","\n","    output_ids = model.generate(\n","        input_ids,\n","        max_length=max_length,\n","        do_sample=True,\n","        top_p=CONFIG['top_p'],\n","        top_k=CONFIG['top_k'],\n","        temperature=CONFIG['temperature'],\n","        pad_token_id=tokenizer.eos_token_id,\n","    )\n","    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","    return generated_text\n","\n","def generate_fewshot_text(topic, model=\"gpt-4\"):\n","    \"\"\"Generate text using few-shot prompting with OpenAI.\"\"\"\n","    full_prompt = FEW_SHOT_PROMPT + f\"\\n\\nTopic: {topic}\"\n","    return generate_with_openai(full_prompt, model=model, max_tokens=1000)\n","\n","print(\"Text generation functions ready!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PsA08rYFp3-V","executionInfo":{"status":"ok","timestamp":1757796955856,"user_tz":-120,"elapsed":90,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"649e0ece-9451-411e-91b4-295d09391d52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Linguistic evaluation functions loaded!\n"]}],"source":["# Linguistic evaluation functions (from eval.py)\n","def cal_lexical(sentences):\n","    \"\"\"Compute lexical features for a list of sentences.\"\"\"\n","    total_nouns = total_verbs = total_adjs = total_subjectivity = total_unique_words = total_concreteness = 0\n","\n","    # Load concreteness data\n","    concreteness_df = pd.read_csv(\"/content/drive/MyDrive/trump_model/data/concreteness.csv\")\n","    concreteness_dict = pd.Series(concreteness_df.Score.values, index=concreteness_df.Word).to_dict()\n","\n","    for s in tqdm(sentences, desc='Calculating lexical features', total=len(sentences)):\n","        words = word_tokenize(s)\n","        pos_tags = nltk.pos_tag(words)\n","        unique_words = set(words)\n","\n","        noun_count = len([word for word, tag in pos_tags if tag.startswith('NN')])\n","        verb_count = len([word for word, tag in pos_tags if tag.startswith('VB')])\n","        adjective_count = len([word for word, tag in pos_tags if tag.startswith('JJ')])\n","\n","        total_nouns += noun_count\n","        total_verbs += verb_count\n","        total_adjs += adjective_count\n","        total_unique_words += len(unique_words)\n","\n","        blob = TextBlob(s)\n","        total_subjectivity += blob.sentiment.subjectivity\n","\n","        total_concreteness += len([word for word in words if concreteness_dict.get(word, 0) > 3])\n","\n","    num_sentences = len(sentences)\n","    avg_nouns = total_nouns / num_sentences\n","    avg_verbs = total_verbs / num_sentences\n","    avg_adjs = total_adjs / num_sentences\n","    avg_unique_words = total_unique_words / num_sentences\n","    avg_subjectivity = total_subjectivity / num_sentences\n","    avg_concreteness = total_concreteness / num_sentences\n","\n","    return [avg_nouns, avg_verbs, avg_adjs, avg_unique_words, avg_subjectivity, avg_concreteness]\n","\n","def get_all_nodes(tree):\n","    \"\"\"Recursively collects all node labels from an NLTK Tree.\"\"\"\n","    nodes = []\n","    for node in tree:\n","        if isinstance(node, Tree):\n","            nodes.append(node.label())\n","            nodes.extend(get_all_nodes(node))\n","    return nodes\n","\n","def cal_syntactic(sentences):\n","    \"\"\"Compute syntactic features for a list of sentences.\"\"\"\n","    cat_dict = {\n","        \"SIMPLE\": 0,\n","        \"COMPOUND\": 0,\n","        \"COMPLEX\": 0,\n","        \"COMPLEX-COMPOUND\": 0,\n","        \"OTHER\": 0\n","    }\n","    nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency', verbose=False)\n","\n","    for s in tqdm(sentences, desc='Calculating syntactic features', total=len(sentences)):\n","        doc = nlp(s)\n","        try:\n","            parse_tree = Tree.fromstring(str(doc.sentences[0].constituency))\n","        except Exception as e:\n","            cat_dict['OTHER'] += 1\n","            continue\n","\n","        sub_tree = parse_tree[0]\n","        l_top = [child.label() for child in sub_tree if isinstance(child, Tree)]\n","        all_nodes = get_all_nodes(parse_tree)\n","\n","        if 'S' in l_top:\n","            if \"SBAR\" not in all_nodes:\n","                cat_dict['COMPOUND'] += 1\n","            else:\n","                cat_dict['COMPLEX-COMPOUND'] += 1\n","        elif 'VP' in l_top:\n","            if \"SBAR\" not in all_nodes:\n","                cat_dict['SIMPLE'] += 1\n","            else:\n","                cat_dict['COMPLEX'] += 1\n","        else:\n","            cat_dict['OTHER'] += 1\n","\n","    total = sum(cat_dict.values())\n","    return [cat_dict[key] / total for key in cat_dict]\n","\n","def cal_surface(sentences):\n","    \"\"\"Compute surface features for a list of sentences.\"\"\"\n","    commas = semicolons = colons = total_words = total_word_length = 0\n","\n","    for s in tqdm(sentences, desc='Calculating surface features', total=len(sentences)):\n","        commas += s.count(',')\n","        semicolons += s.count(';')\n","        colons += s.count(':')\n","\n","        words = s.split()\n","        total_words += len(words)\n","        total_word_length += sum(len(word) for word in words)\n","\n","    num_sentences = len(sentences)\n","    avg_commas = commas / num_sentences if num_sentences else 0\n","    avg_semicolons = semicolons / num_sentences if num_sentences else 0\n","    avg_colons = colons / num_sentences if num_sentences else 0\n","    avg_words_per_sentence = total_words / num_sentences if num_sentences else 0\n","    avg_word_length = total_word_length / total_words if total_words else 0\n","\n","    return [avg_commas, avg_semicolons, avg_colons, avg_words_per_sentence, avg_word_length]\n","\n","print(\"Linguistic evaluation functions loaded!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0Hj_Cj9p3-W","executionInfo":{"status":"ok","timestamp":1757796956387,"user_tz":-120,"elapsed":23,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"c21632e6-0df4-452d-b73d-d21a8653562c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Additional evaluation functions loaded!\n"]}],"source":["# Additional evaluation functions\n","def mean_squared_error(l1, l2):\n","    \"\"\"Computes mean squared error between two lists.\"\"\"\n","    vec1 = np.array(l1)\n","    vec2 = np.array(l2)\n","    return np.mean((vec1 - vec2) ** 2)\n","\n","def jensen_shannon_divergence(l1, l2):\n","    \"\"\"Computes the Jensen-Shannon divergence between two distributions.\"\"\"\n","    vec1 = np.array(l1)\n","    vec2 = np.array(l2)\n","    return jensenshannon(vec1, vec2)\n","\n","def cosine_similarity_of_features(features1, features2):\n","    \"\"\"Compute cosine similarity between combined feature vectors.\"\"\"\n","    combined1 = np.array(features1[0] + features1[1] + features1[2])\n","    combined2 = np.array(features2[0] + features2[1] + features2[2])\n","    norm1 = np.linalg.norm(combined1)\n","    norm2 = np.linalg.norm(combined2)\n","    if norm1 == 0 or norm2 == 0:\n","        return 0.0\n","    return np.dot(combined1, combined2) / (norm1 * norm2)\n","\n","def cal_linguistic_alignment(features1, features2):\n","    \"\"\"Compute linguistic alignment scores between two feature sets.\"\"\"\n","    lexical1, syntactic1, surface1 = features1\n","    lexical2, syntactic2, surface2 = features2\n","\n","    lexical_mse = mean_squared_error(lexical1, lexical2)\n","    surface_mse = mean_squared_error(surface1, surface2)\n","    syntactic_jsd = jensen_shannon_divergence(syntactic1, syntactic2)\n","\n","    return [lexical_mse, syntactic_jsd, surface_mse]\n","\n","def compute_features(text):\n","    \"\"\"Compute all linguistic features for a given text.\"\"\"\n","    sentences = sent_tokenize(text)\n","    lexical = cal_lexical(sentences)\n","    syntactic = cal_syntactic(sentences)\n","    surface = cal_surface(sentences)\n","    return (lexical, syntactic, surface)\n","\n","def average_features(features_list):\n","    \"\"\"Average a list of feature tuples.\"\"\"\n","    avg_lexical = np.mean([feat[0] for feat in features_list], axis=0).tolist()\n","    avg_syntactic = np.mean([feat[1] for feat in features_list], axis=0).tolist()\n","    avg_surface = np.mean([feat[2] for feat in features_list], axis=0).tolist()\n","    return (avg_lexical, avg_syntactic, avg_surface)\n","\n","def load_baseline_texts(csv_path, num_samples=5):\n","    \"\"\"Load baseline Trump speeches from CSV.\"\"\"\n","    df = pd.read_csv(csv_path)\n","    if \"text\" in df.columns:\n","        texts = df[\"text\"].dropna().tolist()\n","    elif \"output\" in df.columns:\n","        texts = df[\"output\"].dropna().tolist()\n","    elif \"speech\" in df.columns:\n","        texts = df[\"speech\"].dropna().tolist()\n","    else:\n","        texts = df.iloc[:, 0].dropna().tolist()\n","\n","    if len(texts) < num_samples:\n","        num_samples = len(texts)\n","    return random.sample(texts, num_samples)\n","\n","print(\"Additional evaluation functions loaded!\")\n"]},{"cell_type":"markdown","metadata":{"id":"2Ivxqc6-p3-W"},"source":["## 5. Test Prompts and Evaluation Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gmc5hdJTp3-W","executionInfo":{"status":"ok","timestamp":1757797014402,"user_tz":-120,"elapsed":56807,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"f595c449-8412-40b0-83a4-7d3935132e92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading baseline Trump speeches...\n","Loaded 10 baseline samples\n","Computing baseline features...\n"]},{"output_type":"stream","name":"stderr","text":["Calculating lexical features: 100%|██████████| 17/17 [00:00<00:00, 100.81it/s]\n","Calculating syntactic features: 100%|██████████| 17/17 [00:02<00:00,  6.51it/s]\n","Calculating surface features: 100%|██████████| 17/17 [00:00<00:00, 113540.08it/s]\n","Calculating lexical features: 100%|██████████| 22/22 [00:00<00:00, 1201.48it/s]\n","Calculating syntactic features: 100%|██████████| 22/22 [00:01<00:00, 11.00it/s]\n","Calculating surface features: 100%|██████████| 22/22 [00:00<00:00, 142840.07it/s]\n","Calculating lexical features: 100%|██████████| 26/26 [00:00<00:00, 1566.68it/s]\n","Calculating syntactic features: 100%|██████████| 26/26 [00:02<00:00, 12.10it/s]\n","Calculating surface features: 100%|██████████| 26/26 [00:00<00:00, 132990.13it/s]\n","Calculating lexical features: 100%|██████████| 22/22 [00:00<00:00, 1292.43it/s]\n","Calculating syntactic features: 100%|██████████| 22/22 [00:01<00:00, 11.01it/s]\n","Calculating surface features: 100%|██████████| 22/22 [00:00<00:00, 122056.47it/s]\n","Calculating lexical features: 100%|██████████| 28/28 [00:00<00:00, 1659.58it/s]\n","Calculating syntactic features: 100%|██████████| 28/28 [00:02<00:00, 13.19it/s]\n","Calculating surface features: 100%|██████████| 28/28 [00:00<00:00, 164944.54it/s]\n","Calculating lexical features: 100%|██████████| 29/29 [00:00<00:00, 1786.78it/s]\n","Calculating syntactic features: 100%|██████████| 29/29 [00:02<00:00, 12.85it/s]\n","Calculating surface features: 100%|██████████| 29/29 [00:00<00:00, 193378.09it/s]\n","Calculating lexical features: 100%|██████████| 27/27 [00:00<00:00, 1556.41it/s]\n","Calculating syntactic features: 100%|██████████| 27/27 [00:02<00:00, 12.85it/s]\n","Calculating surface features: 100%|██████████| 27/27 [00:00<00:00, 170808.76it/s]\n","Calculating lexical features: 100%|██████████| 27/27 [00:00<00:00, 1191.05it/s]\n","Calculating syntactic features: 100%|██████████| 27/27 [00:02<00:00, 12.12it/s]\n","Calculating surface features: 100%|██████████| 27/27 [00:00<00:00, 150393.37it/s]\n","Calculating lexical features: 100%|██████████| 33/33 [00:00<00:00, 1780.97it/s]\n","Calculating syntactic features: 100%|██████████| 33/33 [00:02<00:00, 14.57it/s]\n","Calculating surface features: 100%|██████████| 33/33 [00:00<00:00, 192238.93it/s]\n","Calculating lexical features: 100%|██████████| 29/29 [00:00<00:00, 1707.92it/s]\n","Calculating syntactic features: 100%|██████████| 29/29 [00:02<00:00, 13.44it/s]\n","Calculating surface features: 100%|██████████| 29/29 [00:00<00:00, 142763.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Baseline features computed successfully!\n","Baseline lexical features: [2.146145190922067, 2.2778135150853203, 0.6969261112263141, 11.063962448039527, 0.2802478926458676, 2.0856294220391582]\n","Baseline syntactic features: [0.4918316583123886, 0.09796214603516833, 0.16720270939337875, 0.11181282094060999, 0.13119066531845436]\n","Baseline surface features: [0.9022168500870327, 0.0, 0.0, 9.931276652879088, 4.514]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Test prompts for evaluation\n","TEST_PROMPTS = [\n","    \"Thank you very much, hello Nevada! Hello to all the hardworking American patriots here in Douglas County. We have thousands and thousands of loyal supporters, and 52 days from now, we're going to win Nevada and four more years in the White House.\",\n","\n","    \"Hello Charleston, South Carolina! I'm thrilled to be back in the great state of South Carolina with thousands of hardworking American Patriots who believe in faith, family, God, and country. This is an incredible time for our nation - we're in the midst of the Great American Comeback.\",\n","\n","    \"The fake news media, they've been trying to figure this out for years. They still don't get it though. Look at all those cameras back there. They heard Lindsey and Tim were here and said 'We're not going to attend that rally,' but when they heard those two guys were here, they came running.\",\n","\n","    \"We have the greatest economy in the history of our country - not just our country, but the world. We were beating everybody, including China. Remember when they said China would overtake us in 2019? That didn't work out too well for them. We were doing leaps and bounds until we got hit with the China virus.\"\n","]\n","\n","# Load baseline texts\n","print(\"Loading baseline Trump speeches...\")\n","baseline_texts = load_baseline_texts(CONFIG['baseline_csv'], CONFIG['num_baseline_samples'])\n","print(f\"Loaded {len(baseline_texts)} baseline samples\")\n","\n","# Compute baseline features\n","print(\"Computing baseline features...\")\n","baseline_features_list = [compute_features(text) for text in baseline_texts]\n","baseline_features = average_features(baseline_features_list)\n","\n","print(\"Baseline features computed successfully!\")\n","print(f\"Baseline lexical features: {baseline_features[0]}\")\n","print(f\"Baseline syntactic features: {baseline_features[1]}\")\n","print(f\"Baseline surface features: {baseline_features[2]}\")\n"]},{"cell_type":"markdown","metadata":{"id":"tm9WBU5Tp3-X"},"source":["## 6. Comprehensive Evaluation Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Pe9V73zp3-X","executionInfo":{"status":"ok","timestamp":1757797846257,"user_tz":-120,"elapsed":9,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"caca0afc-53dd-496a-b663-aad0800b100c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Comprehensive evaluation function ready!\n"]}],"source":["\n","def evaluate_model_comparison(prompts, save_results=True):\n","    \"\"\"\n","    Comprehensive evaluation comparing fine-tuned model vs few-shot prompting.\n","    \"\"\"\n","    results = {\n","        'prompts': [],\n","        'finetuned_texts': [],\n","        'fewshot_texts': [],\n","        'finetuned_features': [],\n","        'fewshot_features': [],\n","        'finetuned_scores': [],\n","        'fewshot_scores': [],\n","        'finetuned_cosine_sim': [],\n","        'fewshot_cosine_sim': []\n","    }\n","\n","    print(\"Starting comprehensive evaluation...\")\n","    print(f\"Evaluating {len(prompts)} prompts\")\n","    print(\"=\" * 60)\n","\n","    for i, prompt in enumerate(prompts):\n","        print(f\"\\n--- Evaluating Prompt {i+1}/{len(prompts)}: {prompt} ---\")\n","\n","        # Generate text with fine-tuned model\n","        try:\n","            finetuned_text = generate_finetuned_text(prompt, finetuned_model, finetuned_tokenizer, CONFIG['max_length'])\n","        except Exception as e:\n","            print(f\"Error generating with fine-tuned model: {e}\")\n","            finetuned_text = \"\"\n","\n","        # Generate text with few-shot prompting\n","        try:\n","            fewshot_text = generate_fewshot_text(prompt)\n","        except Exception as e:\n","            print(f\"Error generating with few-shot prompting: {e}\")\n","            fewshot_text = \"\"\n","\n","        # Compute features + metrics\n","        if finetuned_text:\n","            finetuned_features = compute_features(finetuned_text)\n","            finetuned_scores = cal_linguistic_alignment(finetuned_features, baseline_features)\n","            finetuned_cosine = cosine_similarity_of_features(finetuned_features, baseline_features)\n","        else:\n","            finetuned_features, finetuned_scores, finetuned_cosine = None, [float('inf')]*3, 0.0\n","\n","        if fewshot_text:\n","            fewshot_features = compute_features(fewshot_text)\n","            fewshot_scores = cal_linguistic_alignment(fewshot_features, baseline_features)\n","            fewshot_cosine = cosine_similarity_of_features(fewshot_features, baseline_features)\n","        else:\n","            fewshot_features, fewshot_scores, fewshot_cosine = None, [float('inf')]*3, 0.0\n","\n","        # Store results\n","        results['prompts'].append(prompt)\n","        results['finetuned_texts'].append(finetuned_text)\n","        results['fewshot_texts'].append(fewshot_text)\n","        results['finetuned_features'].append(finetuned_features)\n","        results['fewshot_features'].append(fewshot_features)\n","        results['finetuned_scores'].append(finetuned_scores)\n","        results['fewshot_scores'].append(fewshot_scores)\n","        results['finetuned_cosine_sim'].append(finetuned_cosine)\n","        results['fewshot_cosine_sim'].append(fewshot_cosine)\n","\n","        # Add delay to avoid rate limiting\n","        time.sleep(1)\n","\n","    # Save results if requested\n","    if save_results:\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","        # --- Save JSON (safe conversion) ---\n","        serializable_results = {}\n","        for key, value in results.items():\n","            if key in ['finetuned_features', 'fewshot_features']:\n","                # force everything into plain lists\n","                serializable_results[key] = [\n","                    [list(feat[0]), list(feat[1]), list(feat[2])] if feat else None\n","                    for feat in value\n","                ]\n","            else:\n","                serializable_results[key] = value\n","\n","        results_file = f\"/content/drive/MyDrive/trump_model/evaluation_results_{timestamp}.json\"\n","        with open(results_file, 'w') as f:\n","            json.dump(serializable_results, f, indent=2)\n","\n","        print(f\"\\n✅ JSON results saved to: {results_file}\")\n","\n","        # --- Save CSV with examples + metrics ---\n","        rows = []\n","        for i in range(len(prompts)):\n","            rows.append({\n","                \"prompt\": results['prompts'][i],\n","                \"finetuned_text\": results['finetuned_texts'][i],\n","                \"fewshot_text\": results['fewshot_texts'][i],\n","                \"finetuned_lexical_mse\": results['finetuned_scores'][i][0],\n","                \"finetuned_syntactic_jsd\": results['finetuned_scores'][i][1],\n","                \"finetuned_surface_mse\": results['finetuned_scores'][i][2],\n","                \"finetuned_cosine\": results['finetuned_cosine_sim'][i],\n","                \"fewshot_lexical_mse\": results['fewshot_scores'][i][0],\n","                \"fewshot_syntactic_jsd\": results['fewshot_scores'][i][1],\n","                \"fewshot_surface_mse\": results['fewshot_scores'][i][2],\n","                \"fewshot_cosine\": results['fewshot_cosine_sim'][i],\n","            })\n","\n","        df = pd.DataFrame(rows)\n","        csv_file = f\"/content/drive/MyDrive/trump_model/evaluation_results_{timestamp}.csv\"\n","        df.to_csv(csv_file, index=False)\n","\n","        print(f\"✅ CSV results saved to: {csv_file}\")\n","\n","    return results\n","\n","print(\"Comprehensive evaluation function ready!\")\n"]},{"cell_type":"markdown","metadata":{"id":"I4gkeykwp3-Y"},"source":["## 7. Visualization and Analysis Functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GZtiqWip3-Y","executionInfo":{"status":"ok","timestamp":1757797847630,"user_tz":-120,"elapsed":38,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"7d310b4c-f564-43c2-9583-3ad8219e72c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Visualization and analysis functions ready!\n"]}],"source":["def create_comparison_plots(results):\n","    \"\"\"Create comprehensive comparison plots.\"\"\"\n","    # Set up the plotting style\n","    plt.style.use('seaborn-v0_8')\n","    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n","    fig.suptitle('Fine-tuned Model vs Few-shot Prompting: Linguistic Alignment Comparison', fontsize=16, fontweight='bold')\n","\n","    # Extract data for plotting\n","    prompts = results['prompts']\n","    finetuned_lexical = [scores[0] for scores in results['finetuned_scores']]\n","    finetuned_syntactic = [scores[1] for scores in results['finetuned_scores']]\n","    finetuned_surface = [scores[2] for scores in results['finetuned_scores']]\n","    finetuned_cosine = results['finetuned_cosine_sim']\n","\n","    fewshot_lexical = [scores[0] for scores in results['fewshot_scores']]\n","    fewshot_syntactic = [scores[1] for scores in results['fewshot_scores']]\n","    fewshot_surface = [scores[2] for scores in results['fewshot_scores']]\n","    fewshot_cosine = results['fewshot_cosine_sim']\n","\n","    # Plot 1: Lexical MSE Comparison\n","    x = np.arange(len(prompts))\n","    width = 0.35\n","\n","    axes[0, 0].bar(x - width/2, finetuned_lexical, width, label='Fine-tuned', alpha=0.8, color='skyblue')\n","    axes[0, 0].bar(x + width/2, fewshot_lexical, width, label='Few-shot', alpha=0.8, color='lightcoral')\n","    axes[0, 0].set_xlabel('Test Prompts')\n","    axes[0, 0].set_ylabel('Lexical MSE (Lower is Better)')\n","    axes[0, 0].set_title('Lexical Feature Alignment')\n","    axes[0, 0].set_xticks(x)\n","    axes[0, 0].set_xticklabels([f'P{i+1}' for i in range(len(prompts))], rotation=45)\n","    axes[0, 0].legend()\n","    axes[0, 0].grid(True, alpha=0.3)\n","\n","    # Plot 2: Syntactic JSD Comparison\n","    axes[0, 1].bar(x - width/2, finetuned_syntactic, width, label='Fine-tuned', alpha=0.8, color='skyblue')\n","    axes[0, 1].bar(x + width/2, fewshot_syntactic, width, label='Few-shot', alpha=0.8, color='lightcoral')\n","    axes[0, 1].set_xlabel('Test Prompts')\n","    axes[0, 1].set_ylabel('Syntactic JSD (Lower is Better)')\n","    axes[0, 1].set_title('Syntactic Feature Alignment')\n","    axes[0, 1].set_xticks(x)\n","    axes[0, 1].set_xticklabels([f'P{i+1}' for i in range(len(prompts))], rotation=45)\n","    axes[0, 1].legend()\n","    axes[0, 1].grid(True, alpha=0.3)\n","\n","    # Plot 3: Surface MSE Comparison\n","    axes[0, 2].bar(x - width/2, finetuned_surface, width, label='Fine-tuned', alpha=0.8, color='skyblue')\n","    axes[0, 2].bar(x + width/2, fewshot_surface, width, label='Few-shot', alpha=0.8, color='lightcoral')\n","    axes[0, 2].set_xlabel('Test Prompts')\n","    axes[0, 2].set_ylabel('Surface MSE (Lower is Better)')\n","    axes[0, 2].set_title('Surface Feature Alignment')\n","    axes[0, 2].set_xticks(x)\n","    axes[0, 2].set_xticklabels([f'P{i+1}' for i in range(len(prompts))], rotation=45)\n","    axes[0, 2].legend()\n","    axes[0, 2].grid(True, alpha=0.3)\n","\n","    # Plot 4: Cosine Similarity Comparison\n","    axes[1, 0].bar(x - width/2, finetuned_cosine, width, label='Fine-tuned', alpha=0.8, color='skyblue')\n","    axes[1, 0].bar(x + width/2, fewshot_cosine, width, label='Few-shot', alpha=0.8, color='lightcoral')\n","    axes[1, 0].set_xlabel('Test Prompts')\n","    axes[1, 0].set_ylabel('Cosine Similarity (Higher is Better)')\n","    axes[1, 0].set_title('Overall Feature Similarity')\n","    axes[1, 0].set_xticks(x)\n","    axes[1, 0].set_xticklabels([f'P{i+1}' for i in range(len(prompts))], rotation=45)\n","    axes[1, 0].legend()\n","    axes[1, 0].grid(True, alpha=0.3)\n","\n","    # Plot 5: Average Performance Comparison\n","    avg_metrics = {\n","        'Fine-tuned': [\n","            np.mean(finetuned_lexical),\n","            np.mean(finetuned_syntactic),\n","            np.mean(finetuned_surface),\n","            np.mean(finetuned_cosine)\n","        ],\n","        'Few-shot': [\n","            np.mean(fewshot_lexical),\n","            np.mean(fewshot_syntactic),\n","            np.mean(fewshot_surface),\n","            np.mean(fewshot_cosine)\n","        ]\n","    }\n","\n","    metric_names = ['Lexical MSE', 'Syntactic JSD', 'Surface MSE', 'Cosine Sim']\n","    x_metrics = np.arange(len(metric_names))\n","\n","    axes[1, 1].bar(x_metrics - width/2, avg_metrics['Fine-tuned'], width, label='Fine-tuned', alpha=0.8, color='skyblue')\n","    axes[1, 1].bar(x_metrics + width/2, avg_metrics['Few-shot'], width, label='Few-shot', alpha=0.8, color='lightcoral')\n","    axes[1, 1].set_xlabel('Metrics')\n","    axes[1, 1].set_ylabel('Average Score')\n","    axes[1, 1].set_title('Average Performance Across All Prompts')\n","    axes[1, 1].set_xticks(x_metrics)\n","    axes[1, 1].set_xticklabels(metric_names, rotation=45)\n","    axes[1, 1].legend()\n","    axes[1, 1].grid(True, alpha=0.3)\n","\n","    # Plot 6: Win Rate Comparison\n","    finetuned_wins = 0\n","    fewshot_wins = 0\n","\n","    for i in range(len(prompts)):\n","        # Lower MSE/JSD is better, higher cosine similarity is better\n","        lexical_win = finetuned_lexical[i] < fewshot_lexical[i]\n","        syntactic_win = finetuned_syntactic[i] < fewshot_syntactic[i]\n","        surface_win = finetuned_surface[i] < fewshot_surface[i]\n","        cosine_win = finetuned_cosine[i] > fewshot_cosine[i]\n","\n","        total_wins = sum([lexical_win, syntactic_win, surface_win, cosine_win])\n","        if total_wins >= 2:\n","            finetuned_wins += 1\n","        else:\n","            fewshot_wins += 1\n","\n","    win_data = [finetuned_wins, fewshot_wins]\n","    win_labels = ['Fine-tuned', 'Few-shot']\n","    colors = ['skyblue', 'lightcoral']\n","\n","    axes[1, 2].bar(win_labels, win_data, color=colors, alpha=0.8)\n","    axes[1, 2].set_ylabel('Number of Prompts Won')\n","    axes[1, 2].set_title('Head-to-Head Comparison\\n(Wins per Prompt)')\n","    axes[1, 2].grid(True, alpha=0.3)\n","\n","    # Add value labels on bars\n","    for i, v in enumerate(win_data):\n","        axes[1, 2].text(i, v + 0.1, str(v), ha='center', va='bottom', fontweight='bold')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    return fig\n","\n","def print_detailed_analysis(results):\n","    \"\"\"Print detailed analysis of results.\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"DETAILED EVALUATION ANALYSIS\")\n","    print(\"=\"*80)\n","\n","    # Calculate averages\n","    finetuned_lexical_avg = np.mean([scores[0] for scores in results['finetuned_scores']])\n","    finetuned_syntactic_avg = np.mean([scores[1] for scores in results['finetuned_scores']])\n","    finetuned_surface_avg = np.mean([scores[2] for scores in results['finetuned_scores']])\n","    finetuned_cosine_avg = np.mean(results['finetuned_cosine_sim'])\n","\n","    fewshot_lexical_avg = np.mean([scores[0] for scores in results['fewshot_scores']])\n","    fewshot_syntactic_avg = np.mean([scores[1] for scores in results['fewshot_scores']])\n","    fewshot_surface_avg = np.mean([scores[2] for scores in results['fewshot_scores']])\n","    fewshot_cosine_avg = np.mean(results['fewshot_cosine_sim'])\n","\n","    print(f\"\\nAVERAGE PERFORMANCE ACROSS ALL PROMPTS:\")\n","    print(f\"{'Metric':<20} {'Fine-tuned':<15} {'Few-shot':<15} {'Winner':<15}\")\n","    print(\"-\" * 65)\n","\n","    # Lexical MSE (lower is better)\n","    lexical_winner = \"Fine-tuned\" if finetuned_lexical_avg < fewshot_lexical_avg else \"Few-shot\"\n","    print(f\"{'Lexical MSE':<20} {finetuned_lexical_avg:<15.4f} {fewshot_lexical_avg:<15.4f} {lexical_winner:<15}\")\n","\n","    # Syntactic JSD (lower is better)\n","    syntactic_winner = \"Fine-tuned\" if finetuned_syntactic_avg < fewshot_syntactic_avg else \"Few-shot\"\n","    print(f\"{'Syntactic JSD':<20} {finetuned_syntactic_avg:<15.4f} {fewshot_syntactic_avg:<15.4f} {syntactic_winner:<15}\")\n","\n","    # Surface MSE (lower is better)\n","    surface_winner = \"Fine-tuned\" if finetuned_surface_avg < fewshot_surface_avg else \"Few-shot\"\n","    print(f\"{'Surface MSE':<20} {finetuned_surface_avg:<15.4f} {fewshot_surface_avg:<15.4f} {surface_winner:<15}\")\n","\n","    # Cosine Similarity (higher is better)\n","    cosine_winner = \"Fine-tuned\" if finetuned_cosine_avg > fewshot_cosine_avg else \"Few-shot\"\n","    print(f\"{'Cosine Similarity':<20} {finetuned_cosine_avg:<15.4f} {fewshot_cosine_avg:<15.4f} {cosine_winner:<15}\")\n","\n","    # Overall winner\n","    finetuned_wins = sum([\n","        finetuned_lexical_avg < fewshot_lexical_avg,\n","        finetuned_syntactic_avg < fewshot_syntactic_avg,\n","        finetuned_surface_avg < fewshot_surface_avg,\n","        finetuned_cosine_avg > fewshot_cosine_avg\n","    ])\n","\n","    overall_winner = \"Fine-tuned Model\" if finetuned_wins >= 2 else \"Few-shot Prompting\"\n","    print(f\"\\nOVERALL WINNER: {overall_winner} ({finetuned_wins}/4 metrics)\")\n","\n","    # Text length analysis\n","    finetuned_lengths = [len(text) for text in results['finetuned_texts'] if text]\n","    fewshot_lengths = [len(text) for text in results['fewshot_texts'] if text]\n","\n","    print(f\"\\nTEXT LENGTH ANALYSIS:\")\n","    print(f\"Fine-tuned model - Average length: {np.mean(finetuned_lengths):.0f} characters\")\n","    print(f\"Few-shot prompting - Average length: {np.mean(fewshot_lengths):.0f} characters\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","\n","print(\"Visualization and analysis functions ready!\")\n"]},{"cell_type":"markdown","metadata":{"id":"T4yu-jWNp3-a"},"source":["## 8. Run the Complete Evaluation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-fvSWiOp3-a","executionInfo":{"status":"ok","timestamp":1757798038784,"user_tz":-120,"elapsed":190218,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"280bb12c-54eb-4c0a-debd-17c454892435"},"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Starting Comprehensive Trump Speech Style Evaluation\n","============================================================\n","Starting comprehensive evaluation...\n","Evaluating 4 prompts\n","============================================================\n","\n","--- Evaluating Prompt 1/4: Thank you very much, hello Nevada! Hello to all the hardworking American patriots here in Douglas County. We have thousands and thousands of loyal supporters, and 52 days from now, we're going to win Nevada and four more years in the White House. ---\n"]},{"output_type":"stream","name":"stderr","text":["Calculating lexical features: 100%|██████████| 17/17 [00:00<00:00, 1090.31it/s]\n","Calculating syntactic features: 100%|██████████| 17/17 [00:01<00:00, 10.25it/s]\n","Calculating surface features: 100%|██████████| 17/17 [00:00<00:00, 127783.46it/s]\n","Calculating lexical features: 100%|██████████| 56/56 [00:00<00:00, 1657.34it/s]\n","Calculating syntactic features: 100%|██████████| 56/56 [00:04<00:00, 11.95it/s]\n","Calculating surface features: 100%|██████████| 56/56 [00:00<00:00, 227818.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Prompt 2/4: Hello Charleston, South Carolina! I'm thrilled to be back in the great state of South Carolina with thousands of hardworking American Patriots who believe in faith, family, God, and country. This is an incredible time for our nation - we're in the midst of the Great American Comeback. ---\n"]},{"output_type":"stream","name":"stderr","text":["Calculating lexical features: 100%|██████████| 12/12 [00:00<00:00, 932.60it/s]\n","Calculating syntactic features: 100%|██████████| 12/12 [00:01<00:00,  7.76it/s]\n","Calculating surface features: 100%|██████████| 12/12 [00:00<00:00, 99273.47it/s]\n","Calculating lexical features: 100%|██████████| 38/38 [00:00<00:00, 1451.18it/s]\n","Calculating syntactic features: 100%|██████████| 38/38 [00:03<00:00, 10.55it/s]\n","Calculating surface features: 100%|██████████| 38/38 [00:00<00:00, 210268.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Prompt 3/4: The fake news media, they've been trying to figure this out for years. They still don't get it though. Look at all those cameras back there. They heard Lindsey and Tim were here and said 'We're not going to attend that rally,' but when they heard those two guys were here, they came running. ---\n"]},{"output_type":"stream","name":"stderr","text":["Calculating lexical features: 100%|██████████| 22/22 [00:00<00:00, 1525.45it/s]\n","Calculating syntactic features: 100%|██████████| 22/22 [00:01<00:00, 11.79it/s]\n","Calculating surface features: 100%|██████████| 22/22 [00:00<00:00, 146467.76it/s]\n","Calculating lexical features: 100%|██████████| 60/60 [00:00<00:00, 1579.66it/s]\n","Calculating syntactic features: 100%|██████████| 60/60 [00:05<00:00, 11.69it/s]\n","Calculating surface features: 100%|██████████| 60/60 [00:00<00:00, 251910.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Evaluating Prompt 4/4: We have the greatest economy in the history of our country - not just our country, but the world. We were beating everybody, including China. Remember when they said China would overtake us in 2019? That didn't work out too well for them. We were doing leaps and bounds until we got hit with the China virus. ---\n"]},{"output_type":"stream","name":"stderr","text":["Calculating lexical features: 100%|██████████| 17/17 [00:00<00:00, 1362.36it/s]\n","Calculating syntactic features: 100%|██████████| 17/17 [00:01<00:00,  9.31it/s]\n","Calculating surface features: 100%|██████████| 17/17 [00:00<00:00, 138992.53it/s]\n","Calculating lexical features: 100%|██████████| 48/48 [00:00<00:00, 1503.67it/s]\n","Calculating syntactic features: 100%|██████████| 48/48 [00:04<00:00, 11.17it/s]\n","Calculating surface features: 100%|██████████| 48/48 [00:00<00:00, 228520.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ JSON results saved to: /content/drive/MyDrive/trump_model/evaluation_results_20250913_211358.json\n","✅ CSV results saved to: /content/drive/MyDrive/trump_model/evaluation_results_20250913_211358.csv\n","\n","✅ Evaluation completed successfully!\n","Results saved with timestamp: 20250913_211358\n"]}],"source":["# Run the complete evaluation\n","print(\"🚀 Starting Comprehensive Trump Speech Style Evaluation\")\n","print(\"=\" * 60)\n","\n","# Run evaluation on all test prompts\n","results = evaluate_model_comparison(TEST_PROMPTS, save_results=True)\n","\n","print(\"\\n✅ Evaluation completed successfully!\")\n","print(f\"Results saved with timestamp: {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Fwihg56vp3-a"},"source":["## 9. Generate Visualizations and Analysis\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLGaPhAnp3-a"},"outputs":[],"source":["# Generate comprehensive visualizations\n","print(\"📊 Creating comparison visualizations...\")\n","fig = create_comparison_plots(results)\n","\n","# Print detailed analysis\n","print_detailed_analysis(results)\n"]},{"cell_type":"markdown","metadata":{"id":"WKb0XavOp3-a"},"source":["## 10. Individual Text Analysis\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82noiBz0p3-a","executionInfo":{"status":"ok","timestamp":1757798268317,"user_tz":-120,"elapsed":25,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"7137d57c-5ef3-4d2f-c4dd-55e116d2241b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TEXT SAMPLES FOR PROMPT: Thank you very much, hello Nevada! Hello to all the hardworking American patriots here in Douglas County. We have thousands and thousands of loyal supporters, and 52 days from now, we're going to win Nevada and four more years in the White House.\n","================================================================================\n","\n","🔹 FINE-TUNED MODEL OUTPUT:\n","----------------------------------------\n","Thank you very much, hello Nevada! Hello to all the hardworking American patriots here in Douglas County. We have thousands and thousands of loyal supporters, and 52 days from now, we're going to win Nevada and four more years in the White House. It's all over but the shouting.\n","\n","Can we draw the following conclusion?\n","Nevada is a state.\n","\n","Yes, Nevada is a state. The statement provided indicates that the speaker is addressing \"all the hardworking American patriots[s] here in Douglas County\" and then...\n","\n","🔹 FEW-SHOT PROMPTING OUTPUT:\n","----------------------------------------\n","Thank you, thank you very much! Nevada, you are something else. You are something else! And hello Douglas County! Hello to every hardworking patriot that makes up this beautiful part of our country. I see thousands of you out there, thousands and thousands of loyal supporters, and I tell you, we're going to win Nevada! We're going to win four more years in the White House, and it's going to be beautiful. We're going to do it together, folks, just like we always do!\n","\n","You know, our economy is soar...\n","\n","📊 METRICS COMPARISON:\n","----------------------------------------\n","Fine-tuned - Lexical MSE: 4.4009, Syntactic JSD: 0.2199, Surface MSE: 3.8053\n","Few-shot   - Lexical MSE: 0.0645, Syntactic JSD: 0.1638, Surface MSE: 0.1047\n","Cosine Similarity - Fine-tuned: 0.9934, Few-shot: 0.9984\n","\n","================================================================================\n","TEXT SAMPLES FOR PROMPT: Hello Charleston, South Carolina! I'm thrilled to be back in the great state of South Carolina with thousands of hardworking American Patriots who believe in faith, family, God, and country. This is an incredible time for our nation - we're in the midst of the Great American Comeback.\n","================================================================================\n","\n","🔹 FINE-TUNED MODEL OUTPUT:\n","----------------------------------------\n","Hello Charleston, South Carolina! I'm thrilled to be back in the great state of South Carolina with thousands of hardworking American Patriots who believe in faith, family, God, and country. This is an incredible time for our nation - we're in the midst of the Great American Comeback. It started in 2017 when I signed a new Republican agenda that has made our country the envy of the world. We have cut taxes by $1 trillion; built the largest economy in history; fought crime and violence and addict...\n","\n","🔹 FEW-SHOT PROMPTING OUTPUT:\n","----------------------------------------\n","Thank you, Charleston! Thank you, South Carolina! And thank you to every American patriot standing with us tonight—thank you! We're here in this great state with people who believe in faith, family, God, and country—people who make America the greatest nation on earth. And I gotta tell you, I love this state. I love the spirit and the heart of South Carolina.\n","\n","Folks, we're in the middle of something amazing—the Great American Comeback. We've got jobs pouring back into our country—millions of the...\n","\n","📊 METRICS COMPARISON:\n","----------------------------------------\n","Fine-tuned - Lexical MSE: 21.7577, Syntactic JSD: 0.2979, Surface MSE: 23.1547\n","Few-shot   - Lexical MSE: 0.6400, Syntactic JSD: 0.2731, Surface MSE: 0.2640\n","Cosine Similarity - Fine-tuned: 0.9879, Few-shot: 0.9990\n","\n","================================================================================\n","TEXT SAMPLES FOR PROMPT: The fake news media, they've been trying to figure this out for years. They still don't get it though. Look at all those cameras back there. They heard Lindsey and Tim were here and said 'We're not going to attend that rally,' but when they heard those two guys were here, they came running.\n","================================================================================\n","\n","🔹 FINE-TUNED MODEL OUTPUT:\n","----------------------------------------\n","The fake news media, they've been trying to figure this out for years. They still don't get it though. Look at all those cameras back there. They heard Lindsey and Tim were here and said 'We're not going to attend that rally,' but when they heard those two guys were here, they came running. And why? Because it's not real? No. We'd have 100 people here if it wasn't fake. But we are going to have a parade. We've had a great turnout in our parades tonight. I want to thank your sheriffs. I want to s...\n","\n","🔹 FEW-SHOT PROMPTING OUTPUT:\n","----------------------------------------\n","Thank you! Thank you, everybody! I see so many familiar faces in the crowd. Thank you for being here tonight. A special thank you to Senators Lindsey Graham and Tim Scott, two patriots fighting tirelessly for you! And hello to the great state of South Carolina, home to America's hardest workers and bravest patriots! We're here tonight, standing up for faith, family, God, and country. You're the true backbone of America, and together, we're making America great again!\n","\n","You see, folks, the fake ne...\n","\n","📊 METRICS COMPARISON:\n","----------------------------------------\n","Fine-tuned - Lexical MSE: 0.0520, Syntactic JSD: 0.0756, Surface MSE: 0.1980\n","Few-shot   - Lexical MSE: 0.0541, Syntactic JSD: 0.2089, Surface MSE: 0.0466\n","Cosine Similarity - Fine-tuned: 0.9990, Few-shot: 0.9991\n"]}],"source":["# Display individual text samples for detailed analysis\n","def display_text_samples(results, prompt_index=0):\n","    \"\"\"Display text samples for a specific prompt.\"\"\"\n","    if prompt_index >= len(results['prompts']):\n","        print(f\"Invalid prompt index. Available: 0-{len(results['prompts'])-1}\")\n","        return\n","\n","    prompt = results['prompts'][prompt_index]\n","    finetuned_text = results['finetuned_texts'][prompt_index]\n","    fewshot_text = results['fewshot_texts'][prompt_index]\n","\n","    print(f\"\\n{'='*80}\")\n","    print(f\"TEXT SAMPLES FOR PROMPT: {prompt}\")\n","    print(f\"{'='*80}\")\n","\n","    print(f\"\\n🔹 FINE-TUNED MODEL OUTPUT:\")\n","    print(\"-\" * 40)\n","    print(finetuned_text[:500] + \"...\" if len(finetuned_text) > 500 else finetuned_text)\n","\n","    print(f\"\\n🔹 FEW-SHOT PROMPTING OUTPUT:\")\n","    print(\"-\" * 40)\n","    print(fewshot_text[:500] + \"...\" if len(fewshot_text) > 500 else fewshot_text)\n","\n","    print(f\"\\n📊 METRICS COMPARISON:\")\n","    print(\"-\" * 40)\n","    finetuned_scores = results['finetuned_scores'][prompt_index]\n","    fewshot_scores = results['fewshot_scores'][prompt_index]\n","\n","    print(f\"Fine-tuned - Lexical MSE: {finetuned_scores[0]:.4f}, Syntactic JSD: {finetuned_scores[1]:.4f}, Surface MSE: {finetuned_scores[2]:.4f}\")\n","    print(f\"Few-shot   - Lexical MSE: {fewshot_scores[0]:.4f}, Syntactic JSD: {fewshot_scores[1]:.4f}, Surface MSE: {fewshot_scores[2]:.4f}\")\n","    print(f\"Cosine Similarity - Fine-tuned: {results['finetuned_cosine_sim'][prompt_index]:.4f}, Few-shot: {results['fewshot_cosine_sim'][prompt_index]:.4f}\")\n","\n","# Display samples for first few prompts\n","for i in range(min(3, len(results['prompts']))):\n","    display_text_samples(results, i)\n"]},{"cell_type":"markdown","metadata":{"id":"BQiFMpdxp3-b"},"source":["## 11. Quick Test with Single Prompt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJnjY7Zxp3-b","executionInfo":{"status":"ok","timestamp":1757798272451,"user_tz":-120,"elapsed":13,"user":{"displayName":"André","userId":"12772319039599378843"}},"outputId":"a31f3815-b541-4c94-b7df-4a321e274f6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quick test section ready - uncomment the code above to run a single prompt test\n"]}],"source":["# Quick test with a single prompt (uncomment to run)\n","# This is useful for testing before running the full evaluation\n","\n","# test_prompt = \"The economy and job creation\"\n","# print(f\"Testing with prompt: {test_prompt}\")\n","# print(\"=\" * 50)\n","\n","# # Generate with fine-tuned model\n","# print(\"Generating with fine-tuned model...\")\n","# finetuned_test = generate_finetuned_text(test_prompt, finetuned_model, finetuned_tokenizer)\n","# print(f\"Fine-tuned output: {finetuned_test[:200]}...\")\n","\n","# # Generate with few-shot prompting\n","# print(\"\\nGenerating with few-shot prompting...\")\n","# fewshot_test = generate_fewshot_text(test_prompt)\n","# print(f\"Few-shot output: {fewshot_test[:200] if fewshot_test else 'Failed to generate'}...\")\n","\n","print(\"Quick test section ready - uncomment the code above to run a single prompt test\")\n"]},{"cell_type":"markdown","metadata":{"id":"_UhsOv2ip3-b"},"source":["## 12. Summary and Next Steps\n"]},{"cell_type":"markdown","metadata":{"id":"ZxFNaWBSp3-b"},"source":["### What This Notebook Does:\n","\n","1. **Loads both models**: Fine-tuned Trump model and base model for few-shot prompting\n","2. **Implements comprehensive few-shot prompting**: Uses the detailed Trump style examples you provided\n","3. **Evaluates linguistic alignment**: Compares lexical, syntactic, and surface features\n","4. **Generates comprehensive metrics**: MSE, JSD, cosine similarity across multiple test prompts\n","5. **Creates detailed visualizations**: Bar charts, comparison plots, and win-rate analysis\n","6. **Saves results**: Automatically saves evaluation results with timestamps\n","\n","### Key Features:\n","\n","- **8 diverse test prompts** covering different political topics\n","- **OpenAI API integration** for few-shot prompting with GPT-4\n","- **Comprehensive linguistic analysis** using the same metrics as your eval.py\n","- **Side-by-side comparison** of generated texts\n","- **Statistical analysis** with win rates and average performance\n","- **Professional visualizations** for easy interpretation\n","\n","### To Run the Evaluation:\n","\n","1. **Set your OpenAI API key**: `export OPENAI_API_KEY=\"your-key-here\"`\n","2. **Run all cells** in sequence\n","3. **Review the results** in the generated plots and analysis\n","4. **Check saved files** for detailed JSON results\n","\n","### Expected Outputs:\n","\n","- **Comparison plots** showing performance across all metrics\n","- **Detailed analysis** with winner determination\n","- **Text samples** for qualitative evaluation\n","- **JSON results file** with all data for further analysis\n","\n","This notebook provides a complete framework for comparing fine-tuned models against few-shot prompting approaches for style mimicry tasks.\n"]},{"cell_type":"markdown","metadata":{"id":"rLhEsRagp3-c"},"source":[]},{"cell_type":"markdown","metadata":{"id":"cFUhaJqIp3-c"},"source":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"de23e7aa5f314995b7c89f1c87399879":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_221590283afd47f8800296dc5ae69f73","IPY_MODEL_e4ab0f0de7cd4c05a7f1ebc0d7211303","IPY_MODEL_bd69af67145a4e87bb71da7f83f5f06b"],"layout":"IPY_MODEL_8854cf454ead4bb3b4630ea7d5008ec2"}},"221590283afd47f8800296dc5ae69f73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f71294bfeae422f953552f622e3c42e","placeholder":"​","style":"IPY_MODEL_1fffa730b6b648e58ed8fb05153decea","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "}},"e4ab0f0de7cd4c05a7f1ebc0d7211303":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14b9a426a55c4e2bb5858ac24393a2b4","max":53595,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a028836cf18415e9ff889ebc6c4750c","value":53595}},"bd69af67145a4e87bb71da7f83f5f06b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89b96fbc476b451c9ebc9d1be2188ca0","placeholder":"​","style":"IPY_MODEL_8957c3e861d148889dff506c028f1f82","value":" 434k/? [00:00&lt;00:00, 40.2MB/s]"}},"8854cf454ead4bb3b4630ea7d5008ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f71294bfeae422f953552f622e3c42e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fffa730b6b648e58ed8fb05153decea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14b9a426a55c4e2bb5858ac24393a2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a028836cf18415e9ff889ebc6c4750c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89b96fbc476b451c9ebc9d1be2188ca0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8957c3e861d148889dff506c028f1f82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f88e8611064543d0847de4960b519a58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c53e4d885f25438da3b4e55955a31237","IPY_MODEL_849d48bded1241e2b5d2beb4f8540676","IPY_MODEL_41c93904260b4b94b63149c26b4a05fe"],"layout":"IPY_MODEL_8de41910efa94d59a7fd3a2c197951e7"}},"c53e4d885f25438da3b4e55955a31237":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e88f9eb8c7a149ab96546042a97366d4","placeholder":"​","style":"IPY_MODEL_6ba3c3ec3c484a50898a9a0286fac89c","value":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip: 100%"}},"849d48bded1241e2b5d2beb4f8540676":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f68ec3884d64c71bb993920cf678a11","max":526251983,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94136f2345094280a336808c6a49ff7b","value":526251983}},"41c93904260b4b94b63149c26b4a05fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a59e3a4809ba4cb1884d048575d58c5e","placeholder":"​","style":"IPY_MODEL_dda632afe7f644c780797788f48862f9","value":" 526M/526M [00:01&lt;00:00, 429MB/s]"}},"8de41910efa94d59a7fd3a2c197951e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e88f9eb8c7a149ab96546042a97366d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ba3c3ec3c484a50898a9a0286fac89c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f68ec3884d64c71bb993920cf678a11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94136f2345094280a336808c6a49ff7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a59e3a4809ba4cb1884d048575d58c5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda632afe7f644c780797788f48862f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d938276bde8240a9bc3c2acb935f4110":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa0bd3359a6e43b6ade91b852086591f","IPY_MODEL_b705d26e3f85461fb64544b452337f4f","IPY_MODEL_1f3a2acbb3424589bf1b321bdb11d689"],"layout":"IPY_MODEL_13af0579f7f34df3be3ac73965231764"}},"fa0bd3359a6e43b6ade91b852086591f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ab22ddb023843489aba7b3cf59aa347","placeholder":"​","style":"IPY_MODEL_2cfeb6566641444ba9786f23d6bf8078","value":"Loading checkpoint shards: 100%"}},"b705d26e3f85461fb64544b452337f4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_383104f77d02481086dec717da46df0c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f23160ebfe43dc84fce88decc8eac4","value":2}},"1f3a2acbb3424589bf1b321bdb11d689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ed7eb97a1784e60bb8922d2670632ad","placeholder":"​","style":"IPY_MODEL_de1d94a80c4f46a1b677186c1820430c","value":" 2/2 [00:02&lt;00:00,  1.11s/it]"}},"13af0579f7f34df3be3ac73965231764":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ab22ddb023843489aba7b3cf59aa347":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cfeb6566641444ba9786f23d6bf8078":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"383104f77d02481086dec717da46df0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f23160ebfe43dc84fce88decc8eac4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ed7eb97a1784e60bb8922d2670632ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1d94a80c4f46a1b677186c1820430c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a932fc4c6d541e7b5976d79736fc71a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56cd00e7a2ef406ca600c04f9d9df43d","IPY_MODEL_0e5806f10ec240ef800a64ab22bc9b69","IPY_MODEL_7ee1fecf3ca847828f19925a5b7aba9f"],"layout":"IPY_MODEL_69ad5b718e754ae5a70c6200a6db5866"}},"56cd00e7a2ef406ca600c04f9d9df43d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95331fa9a201482f985ddbd2da00a931","placeholder":"​","style":"IPY_MODEL_1e198f0a5b56408eb0986cab13f70d75","value":"Loading checkpoint shards: 100%"}},"0e5806f10ec240ef800a64ab22bc9b69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab2843971c843c59caed66da4efa431","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ba20949ccec47788497e8ee887383c6","value":2}},"7ee1fecf3ca847828f19925a5b7aba9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be8af869f99943a19fc657d5ed7e329e","placeholder":"​","style":"IPY_MODEL_c41919c519c9423e99bbf9907db510dd","value":" 2/2 [00:02&lt;00:00,  1.00s/it]"}},"69ad5b718e754ae5a70c6200a6db5866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95331fa9a201482f985ddbd2da00a931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e198f0a5b56408eb0986cab13f70d75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ab2843971c843c59caed66da4efa431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ba20949ccec47788497e8ee887383c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be8af869f99943a19fc657d5ed7e329e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41919c519c9423e99bbf9907db510dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}